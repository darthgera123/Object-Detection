{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "EffDet_ MASKD.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darthgera123/Object-Detection/blob/master/EffDet_MASKD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fgfa1bjRbVxU",
        "colab_type": "text"
      },
      "source": [
        "# MASKD EfficientDet Training On COCO Dataset\n",
        "This dataset and notebook correspond to the [MASKD Challenge](https://www.aicrowd.com/challenges/aicrowd-blitz-2/problems/maskd) being held on [AIcrowd](https://www.aicrowd.com/).\n",
        "\n",
        "EfficientDet is one of the SOTA in Object detection with Efficient Net as its backbone.We use this [implementation](https://github.com/zylo117/Yet-Another-EfficientDet-Pytorch) for our purposes. Read more about the network [here](https://towardsdatascience.com/efficientdet-scalable-and-efficient-object-detection-review-4472ffc34fd9) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "67-3S5_VTLSL",
        "colab_type": "text"
      },
      "source": [
        "## Install Libraries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "90laRz20TLSN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pycocotools numpy==1.16.0 opencv-python tqdm tensorboard tensorboardX pyyaml webcolors matplotlib\n",
        "!pip install torch==1.4.0\n",
        "!pip install torchvision==0.5.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "JmCQj3rhTLSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "if \"projects\" not in os.getcwd():\n",
        "  !git clone --depth 1 https://github.com/zylo117/Yet-Another-EfficientDet-Pytorch\n",
        "  os.chdir('Yet-Another-EfficientDet-Pytorch')\n",
        "  sys.path.append('.')\n",
        "else:\n",
        "  !git pull\n",
        "\n",
        "\n",
        "# download pretrained weights\n",
        "! wget https://github.com/zylo117/Yet-Another-EfficientDet-Pytorch/releases/download/1.0/efficientdet-d0.pth -O weights/efficientdet-d0.pth\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvAkUNCcdpmS",
        "colab_type": "text"
      },
      "source": [
        "## Download and Prepare Dataset\n",
        "The dataset is supposed to be in a given format. Also we need to create a `projects/masks.yml` which gives relevant info. Eg:\n",
        "```\n",
        "project_name: masks\n",
        "train_set: train\n",
        "val_set: val\n",
        "num_gpus: 1  # 0 means using cpu, 1-N means using gpus \n",
        "\n",
        "# mean and std in RGB order, actually this part should remain unchanged as long as your dataset is similar to coco.\n",
        "mean: [0.485, 0.456, 0.406]\n",
        "std: [0.229, 0.224, 0.225]\n",
        "\n",
        "# this is coco anchors, change it if necessary\n",
        "anchors_scales: '[2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)]'\n",
        "anchors_ratios: '[(1.0, 1.0), (1.4, 0.7), (0.7, 1.4)]'\n",
        "\n",
        "# objects from all labels from your dataset with the order from your annotations.\n",
        "# its index must match your dataset's category_id.\n",
        "# category_id is one_indexed,\n",
        "obj_list: ['mask', 'no_mask']\n",
        "``` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_4Vi6mRosUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -q https://s3.eu-central-1.wasabisys.com/aicrowd-practice-challenges/public/maskd/v0.1/train_images.zip\n",
        "!wget -q https://s3.eu-central-1.wasabisys.com/aicrowd-practice-challenges/public/maskd/v0.1/val_images.zip\n",
        "!wget -q https://s3.eu-central-1.wasabisys.com/aicrowd-practice-challenges/public/maskd/v0.1/test_images.zip\n",
        "!unzip -q train_images.zip\n",
        "!unzip -q val_images.zip\n",
        "!unzip -q test_images.zip\n",
        "!wget -q https://s3.eu-central-1.wasabisys.com/aicrowd-practice-challenges/public/maskd/v0.1/train.json\n",
        "!wget -q https://s3.eu-central-1.wasabisys.com/aicrowd-practice-challenges/public/maskd/v0.1/val.json\n",
        "!wget -q https://s3.eu-central-1.wasabisys.com/aicrowd-practice-challenges/public/maskd/v0.1/test.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0Ezlk4CpKqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir datasets/masks\n",
        "!mv train_images datasets/masks\n",
        "!mv val_images datasets/masks\n",
        "!mv test_images datasets/masks\n",
        "!mkdir datasets/masks/annotations\n",
        "!mv train.json datasets/masks/annotations\n",
        "!mv val.json datasets/masks/annotations\n",
        "!mv test.json datasets/masks/annotations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CazTtDWBp43f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv datasets/masks/annotations/train.json datasets/masks/annotations/instances_train.json\n",
        "!mv datasets/masks/annotations/val.json datasets/masks/annotations/instances_val.json\n",
        "!mv datasets/masks/annotations/test.json datasets/masks/annotations/instances_test.json\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRG3KUoveWrq",
        "colab_type": "text"
      },
      "source": [
        "### Download Pretrained Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDoCzb89SNeu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mkdir weights\n",
        "!wget https://github.com/zylo117/Yet-Another-EfficientDet-Pytorch/releases/download/1.0/efficientdet-d6.pth -O weights/efficientdet-d6.pth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "7Q2onXNZTLSV",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "a-eznEu5TLSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# consider this is a simple dataset, train head will be enough.\n",
        "! python train.py -c 6 -p masks  --lr 1e-3 --batch_size 2 --load_weights weights/efficientdet-d6.pth  --num_epochs 20 --head_only True\n",
        "\n",
        "# the loss will be high at first\n",
        "# don't panic, be patient,\n",
        "# just wait for a little bit longer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "05mjrGRETLSZ",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "9yzNyaSxTLSZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "7f16e0bd-e83f-4b1d-b527-bc7c11878c4d"
      },
      "source": [
        "! python coco_eval.py -c 6 -p masks -w logs/masks/efficientdet-d6_19_6500.pth"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running coco-style evaluation on project masks, weights logs/masks/efficientdet-d6_19_6500.pth...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "100% 120/120 [00:37<00:00,  3.20it/s]\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "BBox\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.32s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.351\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.751\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.237\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.472\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.374\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.347\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.243\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.467\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.503\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.560\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.513\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.487\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "zhV3bNF3TLSc",
        "colab_type": "text"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzC0wr9NATJD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_coco(img_path, set_name, image_ids, coco, model, threshold=0.05):\n",
        "    results = []\n",
        "\n",
        "    regressBoxes = BBoxTransform()\n",
        "    clipBoxes = ClipBoxes()\n",
        "\n",
        "    for image_id in tqdm(image_ids):\n",
        "        image_info = coco.loadImgs(image_id)[0]\n",
        "        image_path = img_path + image_info['file_name']\n",
        "\n",
        "        ori_imgs, framed_imgs, framed_metas = preprocess(image_path, max_size=input_sizes[compound_coef])\n",
        "        x = torch.from_numpy(framed_imgs[0])\n",
        "\n",
        "        if use_cuda:\n",
        "            x = x.cuda(gpu)\n",
        "            if use_float16:\n",
        "                x = x.half()\n",
        "            else:\n",
        "                x = x.float()\n",
        "        else:\n",
        "            x = x.float()\n",
        "\n",
        "        x = x.unsqueeze(0).permute(0, 3, 1, 2)\n",
        "        features, regression, classification, anchors = model(x)\n",
        "\n",
        "        preds = postprocess(x,\n",
        "                            anchors, regression, classification,\n",
        "                            regressBoxes, clipBoxes,\n",
        "                            threshold, nms_threshold)\n",
        "        \n",
        "        if not preds:\n",
        "            continue\n",
        "\n",
        "        preds = invert_affine(framed_metas, preds)[0]\n",
        "\n",
        "        scores = preds['scores']\n",
        "        class_ids = preds['class_ids']\n",
        "        rois = preds['rois']\n",
        "\n",
        "        if rois.shape[0] > 0:\n",
        "            # x1,y1,x2,y2 -> x1,y1,w,h\n",
        "            rois[:, 2] -= rois[:, 0]\n",
        "            rois[:, 3] -= rois[:, 1]\n",
        "\n",
        "            bbox_score = scores\n",
        "\n",
        "            for roi_id in range(rois.shape[0]):\n",
        "                score = float(bbox_score[roi_id])\n",
        "                label = int(class_ids[roi_id])\n",
        "                box = rois[roi_id, :]\n",
        "\n",
        "                image_result = {\n",
        "                    'image_id': image_id,\n",
        "                    'category_id': label + 1,\n",
        "                    'score': float(score),\n",
        "                    'bbox': box.tolist(),\n",
        "                }\n",
        "\n",
        "                results.append(image_result)\n",
        "\n",
        "    if not len(results):\n",
        "        raise Exception('the model does not provide any valid output, check model architecture and the data input')\n",
        "\n",
        "    # write output\n",
        "    filepath = f'test_bbox_results.json'\n",
        "    if os.path.exists(filepath):\n",
        "        os.remove(filepath)\n",
        "    json.dump(results, open(filepath, 'w'), indent=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4XatVW5BDO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "import argparse\n",
        "import torch\n",
        "import yaml\n",
        "from tqdm import tqdm\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "\n",
        "from backbone import EfficientDetBackbone\n",
        "from efficientdet.utils import BBoxTransform, ClipBoxes\n",
        "from utils.utils import preprocess, invert_affine, postprocess, boolean_string\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZkB2REtAajq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "979a59be-44cb-4556-82b2-cebc0593c3f9"
      },
      "source": [
        "project_name = 'masks'\n",
        "\n",
        "params = yaml.safe_load(open(f'projects/{project_name}.yml'))\n",
        "obj_list = params['obj_list']\n",
        "nms_threshold = 0.5\n",
        "weights_path = 'logs/masks/efficientdet-d4_19_6500.pth'\n",
        "compound_coef = 4\n",
        "use_float16 = False\n",
        "SET_NAME = params['val_set']\n",
        "use_cuda = True\n",
        "override_prev_results = True\n",
        "VAL_GT = f'datasets/{params[\"project_name\"]}/annotations/instances_test.json'\n",
        "VAL_IMGS = f'datasets/{params[\"project_name\"]}/test_images/'\n",
        "MAX_IMAGES = 10000\n",
        "coco_gt = COCO(VAL_GT)\n",
        "gpu = 0\n",
        "image_ids = coco_gt.getImgIds()[:MAX_IMAGES]\n",
        "input_sizes = [512, 640, 768, 896, 1024, 1280, 1280, 1536, 1536]\n",
        "\n",
        "if override_prev_results or not os.path.exists(f'test_bbox_results.json'):\n",
        "    model = EfficientDetBackbone(compound_coef=compound_coef, num_classes=len(obj_list),\n",
        "                                  ratios=eval(params['anchors_ratios']), scales=eval(params['anchors_scales']))\n",
        "    model.load_state_dict(torch.load(weights_path, map_location=torch.device('cpu')))\n",
        "    model.requires_grad_(False)\n",
        "    model.eval()\n",
        "\n",
        "    if use_cuda:\n",
        "        model.cuda(gpu)\n",
        "\n",
        "        if use_float16:\n",
        "            model.half()\n",
        "\n",
        "    evaluate_coco(VAL_IMGS, SET_NAME, image_ids, coco_gt, model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 774/774 [01:41<00:00,  7.66it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZaaGX7uBbTq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}